{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8Q12fg_YB2F6"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["#Identifying the target class\n"],"metadata":{"id":"yZTr9DO5O-93"}},{"cell_type":"code","source":["# Ensure dataset is clean and use for processing\n","df = data.copy()\n","\n","# Define the target column and feature set\n","target_col = \"Class\"\n","features = df.drop(columns=[target_col], errors='ignore')\n"],"metadata":{"id":"brXKUo9ZO9jw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Split data into train and test"],"metadata":{"id":"OWjYZSH9PEh3"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Split dataset into training (80%) and testing (20%) sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    features, df[target_col], test_size=0.2, random_state=42, stratify=df[target_col]\n",")"],"metadata":{"id":"daT2PdPnPP0-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Overlap detection and majority samples removal from overlapping region"],"metadata":{"id":"Li6u2TfTRwNU"}},{"cell_type":"code","source":["from itertools import combinations\n","from sklearn.svm import OneClassSVM\n","from sklearn.neighbors import NearestNeighbors\n","\n","\n","# Check the number of unique classes in the target column\n","unique_classes = sorted(df[target_col].unique())\n","\n","# Prepare result storage\n","overlap_results = []\n","\n","# prepare adjacent pairwise classes in the target column\n","\n","#check if target class has only two label (pass or fail)\n","if len(unique_classes) == 2:\n","    class_pairs = [tuple(unique_classes)]\n","# check if there are more than two labels (eg. c1, c2, c3, ...., cn)\n","else:\n","    class_pairs = [(unique_classes[i], unique_classes[i + 1]) for i in range(len(unique_classes) - 1)]\n","\n","# Merge target column back into X_train to ensure alignment\n","X_train[\"Class\"] = y_train.values\n","\n","# Apply One-Class SVM for overlap detection on X_cleaned\n","X_cleaned = X_train.copy()\n","\n","#predict the overlapping instances\n","oc_svm = OneClassSVM(nu=0.07, kernel=\"rbf\", gamma=\"auto\")\n","X_cleaned[\"Overlap_Label\"] = oc_svm.fit_predict(X_cleaned)\n","\n","# Apply Modified Tomek Links for neighborhood detection in Overlap regions\n","k_neighbors = 3  # Set k for nearest neighbors\n","for class_a, class_b in class_pairs:\n","    subset_a = X_cleaned[X_cleaned[\"Class\"] == class_a]\n","    subset_b = X_cleaned[X_cleaned[\"Class\"] == class_b]\n","\n","    if subset_a.empty or subset_b.empty:\n","        continue\n","\n","    # Determine majority (negative) and minority (positive) classes\n","    majority_class, minority_class = (class_a, class_b) if len(subset_a) > len(subset_b) else (class_b, class_a)\n","    majority_subset = X_cleaned[X_cleaned[\"Class\"] == majority_class]\n","    minority_subset = X_cleaned[X_cleaned[\"Class\"] == minority_class]\n","\n","    # Fit nearest neighbors\n","    nn_majority = NearestNeighbors(n_neighbors=k_neighbors).fit(majority_subset.drop(columns=[\"Class\"]))\n","    nn_minority = NearestNeighbors(n_neighbors=k_neighbors).fit(minority_subset.drop(columns=[\"Class\"]))\n","\n","    distances_majority, indices_majority = nn_majority.kneighbors(majority_subset.drop(columns=[\"Class\"]))\n","    distances_minority, indices_minority = nn_minority.kneighbors(minority_subset.drop(columns=[\"Class\"]))\n","\n","    to_remove = set()\n","    for i, neighbors in enumerate(indices_majority):\n","        for neighbor_idx in neighbors:\n","            if neighbor_idx < len(indices_minority):\n","                minority_neighbor_idx = indices_minority[neighbor_idx][0]\n","                if majority_subset.index[i] in minority_subset.index and minority_subset.index[minority_neighbor_idx] in majority_subset.index:\n","                    to_remove.add(majority_subset.index[i])\n","\n","    X_cleaned = X_cleaned.drop(index=to_remove)\n","\n","# Preserve the 'Class' column in the final dataset\n","df_without_overlap = X_cleaned.drop(columns=[\"Overlap_Label\"], errors='ignore')"],"metadata":{"id":"d6XOIjtFHU3D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#CTGAN\n"],"metadata":{"id":"05iiEf0eRdpc"}},{"cell_type":"code","source":["!pip install ctgan"],"metadata":{"id":"0bKyvQD6weW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from ctgan import CTGAN\n","\n","\n","# Identify class distribution\n","class_distribution = df_without_overlap[target_col].value_counts()\n","\n","# Identify the majority class and its sample count\n","majority_class = class_distribution.idxmax()\n","majority_count = class_distribution.max()\n","\n","# Sampling strategy based on imbalance ratio conditions\n","sampling_strategy = {}\n","for cls, count in class_distribution.items():\n","    imbalance_ratio = count / majority_count  # Compute imbalance ratio\n","    if imbalance_ratio < 0.50:  # If the imbalance ratio is more than 50%\n","        sampling_strategy[cls] = int(0.80 * majority_count)\n","\n","# Apply CTGAN-based augmentation only where needed\n","if sampling_strategy:\n","    print(\"Training CTGAN for Imbalance Correction...\")\n","    ctgan = CTGAN(epochs=300, batch_size=32, pac=8, generator_dim=(256, 512, 256), discriminator_dim=(256, 128, 64))\n","    categorical_columns = [df_without_overlap.columns.get_loc(col) for col in df_without_overlap.select_dtypes(include=['category', 'object']).columns]\n","\n","    ctgan.fit(df_without_overlap.drop(columns=[target_col]), categorical_columns)\n","\n","    df_synthetic_ctgan_list = []\n","    for cls, new_count in sampling_strategy.items():\n","        num_samples = new_count - class_distribution[cls]\n","        synthetic_data = ctgan.sample(num_samples)\n","\n","        # Convert to DataFrame and assign synthetic labels\n","        df_synthetic_ctgan = pd.DataFrame(synthetic_data, columns=df_without_overlap.columns)\n","        df_synthetic_ctgan[target_col] = cls  # Assign class label\n","        df_synthetic_ctgan_list.append(df_synthetic_ctgan)\n","\n","    # Combine all synthetic data\n","    df_synthetic_ctgan_final = pd.concat(df_synthetic_ctgan_list, ignore_index=True) if df_synthetic_ctgan_list else pd.DataFrame()\n","\n","    # Merge synthetic data with the original dataset\n","    df_balanced_ctgan = pd.concat([df_without_overlap, df_synthetic_ctgan_final], ignore_index=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVnSeiYAwEol","executionInfo":{"status":"ok","timestamp":1740152806274,"user_tz":0,"elapsed":224865,"user":{"displayName":"John-Bosco Diekuu","userId":"08907168290617559231"}},"outputId":"bea501d0-a3a5-4249-bc86-0ed7d091d94f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training CTGAN for Imbalance Correction...\n"]}]},{"cell_type":"markdown","source":["# Evaluation metrics\n"],"metadata":{"id":"j910C_LYSVBy"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, balanced_accuracy_score, recall_score, f1_score, confusion_matrix\n","from imblearn.metrics import geometric_mean_score\n","from scipy.stats import entropy\n","\n","# Function to calculate G-Mean\n","def g_mean_score(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred)\n","    sensitivity = cm.diagonal() / cm.sum(axis=1)\n","    g_mean = np.sqrt(np.prod(sensitivity))\n","    return g_mean\n","\n","# Compute Class Balance Accuracy (CBA)\n","def class_balance_accuracy(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred)\n","    num_classes = cm.shape[0]\n","    cba = np.sum([np.max(cm[i, :]) / np.sum(cm[i, :]) for i in range(num_classes)]) / num_classes\n","    return cba\n","\n","def compute_mean_sensitivity(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred)\n","    TP = np.diag(cm)\n","    FN = np.sum(cm, axis=1) - TP\n","    sensitivities = TP / (TP + FN + 1e-10)\n","    return np.mean(sensitivities)\n","\n","\n","def confusion_entropy(y_true, y_pred):\n","   # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred).astype(float)\n","    C = cm.shape[0]  # Number of classes\n","\n","    # Compute class probabilities (Pj)\n","    row_sums = np.sum(cm, axis=1, keepdims=True)  # Sum of instances per actual class\n","    Pj = np.sum(cm, axis=1) / (2 * np.sum(cm))  # Class probability weighting\n","\n","    # Compute normalized confusion probabilities (Pij)\n","    Pij = np.maximum(cm / (row_sums + 1e-9), 1e-9)  # Prevent division by zero and log(0)\n","\n","    # Compute CEN_j for each class\n","    CEN_j = -np.sum(\n","        Pij * np.log2(np.maximum(Pij, 1e-9)) + (1 - Pij) * np.log2(np.maximum(1 - Pij, 1e-9)),\n","        axis=1\n","    )\n","\n","    # Compute final Confusion Entropy score\n","    CEN = np.sum(Pj * CEN_j)\n","\n","    # Normalize to [0,1] by dividing by log2(C) (max entropy possible)\n","    CEN_normalized = CEN / np.log2(C + 1e-9)  # Ensure valid normalization\n","\n","    return np.clip(CEN_normalized, 0, 1)"],"metadata":{"id":"3qtDwoMICXYg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Cross validation"],"metadata":{"id":"2l8sGamdjXqi"}},{"cell_type":"code","source":["# ---- Cross-Validation ----\n","def evaluate_with_cv(X, y, n_splits=5):\n","    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","    results = {\n","        'Class Balance Accuracy': [],\n","        'G-Mean': [],\n","        'Mean Sensitivity': [],\n","        'CEN': []\n","    }"],"metadata":{"id":"8p3MHeYqjXNy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Random Forest"],"metadata":{"id":"m9EtmUApk85i"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n","        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n","        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n","\n","        rf_classifier = RandomForestClassifier(n_estimators=500, random_state=42)\n","        rf_classifier.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        results['Class Balance Accuracy'].append(class_balance_accuracy(y_test, y_pred))\n","        results['G-Mean'].append(geometric_mean_score(y_test, y_pred, average='macro'))\n","        results['Mean Sensitivity'].append(compute_mean_sensitivity(y_test, y_pred))\n","        results['CEN'].append(confusion_entropy(y_test, y_pred))\n","\n","        print(f\"Fold {fold} completed.\")\n","\n","    return pd.DataFrame(results).mean().to_frame(name='Average').T\n","\n","# ---- Run it ----\n","target_col = 'Class'  # change if needed\n","X = df_balanced_ctgan.drop(columns=[target_col])\n","y = df_balanced_ctgan[target_col]\n","\n","final_metrics = evaluate_with_cv(X, y)\n","print(final_metrics)"],"metadata":{"id":"Rd3pnrFAk4S2"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"10RKszU6wEEbu2FP-UM1DIgP8LY-UAyYy","timestamp":1739879071944},{"file_id":"1nuEjZeR73DQq8UGP10WLtqhzE9p5xs4V","timestamp":1739703867450},{"file_id":"1Mbp-sTSrhhSWelaAd6UBLRzP2witzjBQ","timestamp":1739624841206},{"file_id":"1FZGZy55B5aY5k2rivj1YUCNFvet1CmIo","timestamp":1739463053167},{"file_id":"1RDenHcWR7nncRo9haM0ZThLnl2Tkc4fJ","timestamp":1739275891921},{"file_id":"1igD06C0POOZFPRHxrpzOI5p_v0qOzSjt","timestamp":1738933577441},{"file_id":"1Bta9u_z-93Vpm1tFIhmIw39uK3AV1zxm","timestamp":1714656453022},{"file_id":"1pHp60WKPkPWt3yTdHUY4IRpCA7zAk3g5","timestamp":1714297538122},{"file_id":"1pXy3zJcIUlmKZMdzAaEAKtN3lVQzXSh_","timestamp":1714043491837},{"file_id":"1y9KqeFAKWBiPdg1L7XWqdJT-on_lyWoc","timestamp":1714037639789},{"file_id":"1279AlLUkKKgEaBy0GsVr76KLjWdA1D9N","timestamp":1713530102009},{"file_id":"1QLvEPF-DvL22_FD3WtaIpSYRGjuOa_sV","timestamp":1713370386433},{"file_id":"1gWvSkv5IdbtbYkl2By-ET6LOZROR0ao1","timestamp":1712315806424},{"file_id":"1DURPj0peuCWRZkCdPNxanGav78bp13Uf","timestamp":1707932689975},{"file_id":"1F8szZ4Ghrt0GqEHYU1cE1AgwVRlH6gqH","timestamp":1707604424236},{"file_id":"1MUcuApf8EODGbmOa_mlw8Xh-56s4XBXw","timestamp":1707262764792}],"authorship_tag":"ABX9TyOrS0V3L3+MaGr5wLFiKNqA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}